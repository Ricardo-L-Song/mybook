# pythonçˆ¬è™«çˆ¬å–è±†ç“£ç”µå½±

æœ€è¿‘ä¹°äº†ã€Špythonç¼–ç¨‹ä»å…¥é—¨åˆ°å®è·µã€‹ï¼Œæƒ³ä¹‹åå†™ä¸¤ç¯‡æ–‡ç« ï¼Œä¸€ç¯‡æ•°æ®å¯è§†åŒ–ï¼Œä¸€ç¯‡python webï¼Œä»Šå¤©è¿™ç¯‡å°±å½“pythonå…¥é—¨å§ã€‚

#### ä¸€.å‰æœŸå‡†å¤‡:

IDEå‡†å¤‡:[pycharm](https://www.jetbrains.com/pycharm/) å¯¼å…¥çš„pythonåº“ï¼šrequestsç”¨äºè¯·æ±‚ï¼ŒBeautifulSoupç”¨äºç½‘é¡µè§£æ

#### äºŒ.å®ç°æ­¥éª¤

**1.ä¼ å…¥url**

**2.è§£æè¿”å›çš„æ•°æ®**

**3.ç­›é€‰**

**4.éå†æå–æ•°æ®**

#### ä¸‰.ä»£ç å®ç°

```text
import requests # å¯¼å…¥ç½‘é¡µè¯·æ±‚åº“
from bs4 import BeautifulSoup # å¯¼å…¥ç½‘é¡µè§£æåº“

# ä¼ å…¥URL
r = requests.get("https://movie.douban.com/top250")

# è§£æè¿”å›çš„æ•°æ®
soup=BeautifulSoup(r.content,"html.parser")

#æ‰¾åˆ°divä¸­ï¼Œclasså±æ€§ä¸ºitemçš„div
movie_list=soup.find_all("div",class_="item")

#éå†æå–æ•°æ®
for movie in movie_list:
    title=movie.find("span",class_="title").text
    rating_num=movie.find("span",class_="rating_num").text
    inq=movie.find("span",class_="inq").text
    star = movie.find('div', class_='star')
    comment_num = star.find_all('span')[-1].text
    print(title, rating_num, '\n', comment_num, inq, '\n')
```

ä»¥titleå˜é‡ä¸ºä¾‹ï¼Œæˆ‘ä»¬æ‰¾åˆ°äº†divä¸­ï¼Œclasså±æ€§ä¸ºitemçš„divï¼Œç„¶ååœ¨æ­¤divä¸­ï¼Œç­›é€‰å‡ºclassåä¸ºtitleçš„spanï¼Œè·å–æ–‡æœ¬å†…å®¹ï¼Œæ‰“å°ï¼ˆcomment\_numæ¯”è¾ƒç‰¹æ®Šï¼Œå› ä¸ºå…¶åœ¨starçš„divä¸‹ï¼Œæ²¡æœ‰classå±æ€§ï¼Œä¸ºdivä¸­æœ€åä¸€ä¸ªspanï¼Œæ‰€ä»¥æˆ‘ä»¬å–å‡ºstarå±‚çº§ä¸­æœ€åä¸€ä¸ªspanï¼Œå˜ä¸ºæ–‡æœ¬ï¼‰ï¼Œä»¥ä¸‹æ˜¯è¾“å‡ºç»“æœã€‚ ![&#x8C46;&#x74E3;.JPG](https://upload-images.jianshu.io/upload_images/9003228-d01fc576385b1df5.JPG?imageMogr2/auto-orient/strip|imageView2/2/w/1240)

#### å››.å¯¹è·å–åˆ°çš„æ•°æ®è¿›è¡Œæ•´åˆ

**1.æ•´åˆæˆåˆ—è¡¨**

**2.æ•´åˆæˆjsonæ–‡ä»¶**

**3.å®šä¹‰ä¸ºå‡½æ•°å½¢å¼**

1.æ•´åˆæˆåˆ—è¡¨

```text
import requests # å¯¼å…¥ç½‘é¡µè¯·æ±‚åº“
from bs4 import BeautifulSoup # å¯¼å…¥ç½‘é¡µè§£æåº“
import pprint # è§„èŒƒæ˜¾ç¤ºåˆ—è¡¨çš„æ’ä»¶åº“

# ä¼ å…¥URL
r = requests.get("https://movie.douban.com/top250")

# è§£æè¿”å›çš„æ•°æ®
soup=BeautifulSoup(r.content,"html.parser")

#æ‰¾åˆ°divä¸­ï¼Œclasså±æ€§ä¸ºitemçš„div
movie_list=soup.find_all("div",class_="item")

#åˆ›å»ºå­˜å‚¨ç»“æœçš„ç©ºåˆ—è¡¨
result_list=[]

#éå†æå–æ•°æ®
for movie in movie_list:
    #åˆ›å»ºå­—å…¸
    dict={}
    dict["title"]=movie.find("span",class_="title").text
    dict["dictrating_num"]=movie.find("span",class_="rating_num").text
    dict["inq"]=movie.find("span",class_="inq").text
    star = movie.find('div', class_='star')
    dict["comment_num"] = star.find_all('span')[-1].text
    result_list.append(dict)

    # æ˜¾ç¤ºç»“æœ
pp = pprint.PrettyPrinter(indent=4)
pp.pprint(result_list)
```

æ§åˆ¶å°æ˜¾ç¤ºçš„ç»“æœ: ![&#x5217;&#x8868;.JPG](https://upload-images.jianshu.io/upload_images/9003228-6295daf257228424.JPG?imageMogr2/auto-orient/strip|imageView2/2/w/1240)

2.æ•´åˆæˆJSONæ–‡ä»¶

```text
import requests # å¯¼å…¥ç½‘é¡µè¯·æ±‚åº“
import json# ç”¨äºå°†åˆ—è¡¨å­—å…¸ï¼ˆjsonæ ¼å¼ï¼‰è½¬åŒ–ä¸ºç›¸åŒå½¢å¼å­—ç¬¦ä¸²ï¼Œä»¥ä¾¿å­˜å…¥æ–‡ä»¶
from bs4 import BeautifulSoup # å¯¼å…¥ç½‘é¡µè§£æåº“


# ä¼ å…¥URL
r = requests.get("https://movie.douban.com/top250")

# è§£æè¿”å›çš„æ•°æ®
soup=BeautifulSoup(r.content,"html.parser")

#æ‰¾åˆ°divä¸­ï¼Œclasså±æ€§ä¸ºitemçš„div
movie_list=soup.find_all("div",class_="item")

#åˆ›å»ºå­˜å‚¨ç»“æœçš„ç©ºåˆ—è¡¨
result_list=[]

#éå†æå–æ•°æ®
for movie in movie_list:
    #åˆ›å»ºå­—å…¸
    dict={}
    dict["title"]=movie.find("span",class_="title").text
    dict["dictrating_num"]=movie.find("span",class_="rating_num").text
    dict["inq"]=movie.find("span",class_="inq").text
    star = movie.find('div', class_='star')
    dict["comment_num"] = star.find_all('span')[-1].text
    result_list.append(dict)

    # æ˜¾ç¤ºç»“æœ
# å°†result_listè¿™ä¸ªjsonæ ¼å¼çš„pythonå¯¹è±¡è½¬åŒ–ä¸ºå­—ç¬¦ä¸²
s = json.dumps(result_list, indent = 4, ensure_ascii=False)
# å°†å­—ç¬¦ä¸²å†™å…¥æ–‡ä»¶
with open('movies.json', 'w', encoding = 'utf-8') as f:
    f.write(s)
```

ç»“æœ: ![json.JPG](https://upload-images.jianshu.io/upload_images/9003228-53a4a638dfb28ab8.JPG?imageMogr2/auto-orient/strip|imageView2/2/w/1240)

3.å®šä¹‰æˆå‡½æ•°

```text
import requests # å¯¼å…¥ç½‘é¡µè¯·æ±‚åº“
import json# ç”¨äºå°†åˆ—è¡¨å­—å…¸ï¼ˆjsonæ ¼å¼ï¼‰è½¬åŒ–ä¸ºç›¸åŒå½¢å¼å­—ç¬¦ä¸²ï¼Œä»¥ä¾¿å­˜å…¥æ–‡ä»¶
from bs4 import BeautifulSoup # å¯¼å…¥ç½‘é¡µè§£æåº“

# ç”¨äºå‘é€è¯·æ±‚ï¼Œè·å¾—ç½‘é¡µæºä»£ç ä»¥ä¾›è§£æ
def start_requests(url):
    r = requests.get(url)
    return r.content

# è§£æè¿”å›çš„æ•°æ®
def parse(text):
    soup=BeautifulSoup(text,"html.parser")
    movie_list=soup.find_all("div",class_="item")
    result_list=[]
    for movie in movie_list:
    #åˆ›å»ºå­—å…¸
        dict={}
        dict["title"]=movie.find("span",class_="title").text
        dict["dictrating_num"]=movie.find("span",class_="rating_num").text
        dict["inq"]=movie.find("span",class_="inq").text
        star = movie.find('div', class_='star')
        dict["comment_num"] = star.find_all('span')[-1].text
        result_list.append(dict)
    return result_list

    #å°†æ•°æ®å†™å…¥jsonæ–‡ä»¶
def write_json(result):
    s = json.dumps(result, indent = 4, ensure_ascii=False)
    with open('movies1.json', 'w', encoding = 'utf-8') as f:
        f.write(s)

# ä¸»è¿è¡Œå‡½æ•°ï¼Œè°ƒç”¨å…¶ä»–å‡½æ•°
def main():
    url = 'https://movie.douban.com/top250'
    text = start_requests(url)
    result = parse(text)
    write_json(result)

if __name__ == '__main__':
    main()
```

ç»“æœ: ![&#x51FD;&#x6570;.JPG](https://upload-images.jianshu.io/upload_images/9003228-84c349cf94c4d7b7.JPG?imageMogr2/auto-orient/strip|imageView2/2/w/1240)

è§‰å¾—æœ‰ç”¨çš„è¯å°±ç»™é¢—å°ğŸ’—ğŸ’—å§~

